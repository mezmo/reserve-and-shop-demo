# OpenTelemetry Collector Configuration Examples
# Complete YAML configurations for different deployment scenarios

# ===== BASIC CONFIGURATION =====

# Basic single-pipeline configuration for logs only
basic_logs_only: |
  receivers:
    filelog:
      include:
        - /tmp/codeuser/*.log
      start_at: beginning

  processors:
    batch:
      timeout: 1s
      send_batch_size: 100

  exporters:
    logging:
      loglevel: info
    
    file:
      path: /tmp/codeuser/otel-output.json

  service:
    pipelines:
      logs:
        receivers: [filelog]
        processors: [batch]
        exporters: [logging, file]

---

# ===== MULTI-PIPELINE CONFIGURATIONS =====

# Complete multi-pipeline setup with logs, metrics, and traces
multi_pipeline_complete: |
  receivers:
    # File-based log ingestion
    filelog:
      include:
        - /tmp/codeuser/access.log
        - /tmp/codeuser/events.log
        - /tmp/codeuser/performance.log
        - /tmp/codeuser/restaurant-performance.log
        - /tmp/codeuser/errors.log
        - /tmp/codeuser/metrics.log
        - /tmp/codeuser/app.log
      start_at: beginning
      include_file_name: false
      include_file_path: true
      operators:
        - type: add
          field: attributes.log_type
          value: structured
        - type: add
          field: attributes.service
          value: restaurant-app
        - type: add
          field: attributes.environment
          value: demo

    # Host system metrics
    hostmetrics:
      collection_interval: 30s
      scrapers:
        cpu:
          metrics:
            system.cpu.utilization:
              enabled: true
            system.cpu.time:
              enabled: true
        memory:
          metrics:
            system.memory.usage:
              enabled: true
            system.memory.utilization:
              enabled: true
        disk:
          metrics:
            system.disk.io:
              enabled: true
            system.disk.operations:
              enabled: true
        filesystem:
          metrics:
            system.filesystem.usage:
              enabled: true
            system.filesystem.utilization:
              enabled: true
        network:
          metrics:
            system.network.io:
              enabled: true
            system.network.connections:
              enabled: true

    # Application traces
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318
          cors:
            allowed_origins:
              - http://localhost:8080
              - http://localhost:3000
              - http://localhost:3001
            allowed_headers: ['*']
            max_age: 7200

  processors:
    # Batch processing for efficiency
    batch:
      timeout: 1s
      send_batch_size: 1024
      send_batch_max_size: 2048

    # Resource attribution
    resource:
      attributes:
        - key: service.name
          value: restaurant-app
          action: upsert
        - key: service.version
          value: 1.0.0
          action: upsert
        - key: deployment.environment
          value: demo
          action: upsert
        - key: service.tags
          value: restaurant-app,otel,nodejs
          action: upsert
        - key: service.instance.id
          value: restaurant-app-001
          action: upsert

    # Memory limiter to prevent OOM
    memory_limiter:
      limit_mib: 256
      spike_limit_mib: 64
      check_interval: 1s

  exporters:
    # Debug exporters
    logging:
      loglevel: info
      
    file/logs:
      path: /tmp/codeuser/otel-logs-debug.json
      format: json

    file/metrics:
      path: /tmp/codeuser/otel-metrics-debug.json
      format: json

    file/traces:
      path: /tmp/codeuser/otel-traces-debug.json
      format: json

    # Mezmo Pipeline exporters (modern approach)
    otlphttp/logs:
      logs_endpoint: https://pipeline.mezmo.com/v1/YOUR_LOGS_PIPELINE_ID
      headers:
        authorization: YOUR_LOGS_INGESTION_KEY
        content-type: application/x-protobuf
      timeout: 30s
      compression: gzip

    otlphttp/metrics:
      endpoint: https://pipeline.mezmo.com/v1/YOUR_METRICS_PIPELINE_ID
      headers:
        authorization: YOUR_METRICS_INGESTION_KEY
        content-type: application/x-protobuf
      timeout: 30s
      compression: gzip

    otlphttp/traces:
      endpoint: https://pipeline.mezmo.com/v1/YOUR_TRACES_PIPELINE_ID
      headers:
        authorization: YOUR_TRACES_INGESTION_KEY
        content-type: application/x-protobuf
      timeout: 30s
      compression: gzip

    # Legacy LogDNA exporters (fallback)
    mezmo/logs:
      ingest_url: https://logs.mezmo.com/otel/ingest/rest
      ingest_key: YOUR_LEGACY_INGESTION_KEY

  service:
    pipelines:
      logs:
        receivers: [filelog]
        processors: [memory_limiter, resource, batch]
        exporters: [file/logs, otlphttp/logs]

      metrics:
        receivers: [hostmetrics]
        processors: [memory_limiter, resource, batch]
        exporters: [file/metrics, otlphttp/metrics]

      traces:
        receivers: [otlp]
        processors: [memory_limiter, resource, batch]
        exporters: [file/traces, otlphttp/traces]

    extensions: [health_check, pprof]
    telemetry:
      logs:
        level: info
      metrics:
        address: 0.0.0.0:8888
        level: detailed

  extensions:
    health_check:
      endpoint: 0.0.0.0:13133
    pprof:
      endpoint: 0.0.0.0:1777

---

# ===== PRODUCTION OPTIMIZED CONFIGURATION =====

# High-performance production configuration
production_optimized: |
  receivers:
    filelog:
      include:
        - /var/log/restaurant-app/*.log
      start_at: end  # Only new logs in production
      max_log_size: 1MiB
      max_concurrent_files: 10
      operators:
        - type: add
          field: attributes.environment
          value: production

    hostmetrics:
      collection_interval: 60s  # Less frequent in production
      scrapers:
        cpu: {}
        memory: {}
        disk: {}
        filesystem: {}

    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
          max_recv_msg_size: 4194304  # 4MB
        http:
          endpoint: 0.0.0.0:4318
          max_request_body_size: 4194304  # 4MB

  processors:
    # Larger batches for efficiency
    batch:
      timeout: 5s
      send_batch_size: 2048
      send_batch_max_size: 4096

    # Resource attribution
    resource:
      attributes:
        - key: service.name
          value: restaurant-app
          action: upsert
        - key: deployment.environment
          value: production
          action: upsert

    # Memory management for production
    memory_limiter:
      limit_mib: 1024
      spike_limit_mib: 256

    # Probabilistic sampling for traces (reduce volume)
    probabilistic_sampler:
      sampling_percentage: 10  # Sample 10% of traces

  exporters:
    # Production Mezmo exports
    otlphttp/logs:
      logs_endpoint: https://pipeline.mezmo.com/v1/PROD_LOGS_PIPELINE_ID
      headers:
        authorization: PROD_LOGS_INGESTION_KEY
        content-type: application/x-protobuf
      timeout: 30s
      compression: gzip
      retry_on_failure:
        enabled: true
        initial_interval: 1s
        max_interval: 30s
        max_elapsed_time: 300s

    otlphttp/metrics:
      endpoint: https://pipeline.mezmo.com/v1/PROD_METRICS_PIPELINE_ID
      headers:
        authorization: PROD_METRICS_INGESTION_KEY
        content-type: application/x-protobuf
      timeout: 30s
      compression: gzip
      retry_on_failure:
        enabled: true
        initial_interval: 1s
        max_interval: 30s

    otlphttp/traces:
      endpoint: https://pipeline.mezmo.com/v1/PROD_TRACES_PIPELINE_ID
      headers:
        authorization: PROD_TRACES_INGESTION_KEY
        content-type: application/x-protobuf
      timeout: 30s
      compression: gzip
      retry_on_failure:
        enabled: true
        initial_interval: 1s
        max_interval: 30s

  service:
    pipelines:
      logs:
        receivers: [filelog]
        processors: [memory_limiter, resource, batch]
        exporters: [otlphttp/logs]

      metrics:
        receivers: [hostmetrics]
        processors: [memory_limiter, resource, batch]
        exporters: [otlphttp/metrics]

      traces:
        receivers: [otlp]
        processors: [memory_limiter, probabilistic_sampler, resource, batch]
        exporters: [otlphttp/traces]

    extensions: [health_check]
    telemetry:
      logs:
        level: warn  # Reduce collector's own logging
      metrics:
        address: 0.0.0.0:8888

  extensions:
    health_check:
      endpoint: 0.0.0.0:13133
      check_collector_pipeline:
        enabled: true
        interval: 30s
        exporter_failure_threshold: 5

---

# ===== DEVELOPMENT CONFIGURATION =====

# Development-friendly configuration with debug features
development_debug: |
  receivers:
    filelog:
      include:
        - /tmp/codeuser/*.log
      start_at: beginning
      poll_interval: 200ms  # Frequent polling for development
      operators:
        - type: add
          field: attributes.environment
          value: development
        - type: add
          field: attributes.debug_mode
          value: true

    hostmetrics:
      collection_interval: 10s  # More frequent for development
      scrapers:
        cpu: {}
        memory: {}

    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318
          cors:
            allowed_origins: ['*']  # Permissive CORS for development

  processors:
    # Small batches for immediate feedback
    batch:
      timeout: 500ms
      send_batch_size: 100

    resource:
      attributes:
        - key: service.name
          value: restaurant-app-dev
          action: upsert
        - key: deployment.environment
          value: development
          action: upsert
        - key: developer.name
          value: ${DEV_NAME}
          action: upsert

  exporters:
    # Console output for immediate feedback
    logging:
      loglevel: debug

    # File outputs for inspection
    file/logs:
      path: /tmp/codeuser/dev-logs.json
      format: json

    file/metrics:
      path: /tmp/codeuser/dev-metrics.json
      format: json

    file/traces:
      path: /tmp/codeuser/dev-traces.json
      format: json

  service:
    pipelines:
      logs:
        receivers: [filelog]
        processors: [resource, batch]
        exporters: [logging, file/logs]

      metrics:
        receivers: [hostmetrics]
        processors: [resource, batch]
        exporters: [logging, file/metrics]

      traces:
        receivers: [otlp]
        processors: [resource, batch]
        exporters: [logging, file/traces]

    telemetry:
      logs:
        level: debug  # Verbose logging for development
      metrics:
        address: 0.0.0.0:8888

---

# ===== SPECIALIZED CONFIGURATIONS =====

# High-volume logs configuration
high_volume_logs: |
  receivers:
    filelog:
      include:
        - /var/log/nginx/access.log
        - /var/log/nginx/error.log
        - /tmp/codeuser/*.log
      start_at: end
      max_concurrent_files: 20
      operators:
        - type: regex_parser
          regex: '^(?P<timestamp>\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}) \[(?P<level>\w+)\] (?P<message>.*)'
          timestamp:
            parse_from: attributes.timestamp
            layout: '%Y-%m-%d %H:%M:%S'

  processors:
    # Large batches for high volume
    batch:
      timeout: 10s
      send_batch_size: 5000
      send_batch_max_size: 10000

    # Sampling to reduce volume
    probabilistic_sampler:
      sampling_percentage: 1  # Sample 1% of high-volume logs

    # Filter out noisy logs
    filter:
      logs:
        exclude:
          match_type: strict
          bodies: ["health check", "ping", "heartbeat"]

    resource:
      attributes:
        - key: log_type
          value: high_volume
          action: upsert

  exporters:
    otlphttp/logs:
      logs_endpoint: https://pipeline.mezmo.com/v1/HIGH_VOLUME_PIPELINE_ID
      headers:
        authorization: HIGH_VOLUME_INGESTION_KEY
      compression: gzip
      timeout: 60s

  service:
    pipelines:
      logs:
        receivers: [filelog]
        processors: [probabilistic_sampler, filter, resource, batch]
        exporters: [otlphttp/logs]

---

# Security-focused configuration
security_focused: |
  receivers:
    filelog:
      include:
        - /var/log/security/*.log
        - /var/log/auth.log
        - /tmp/codeuser/errors.log
      operators:
        - type: add
          field: attributes.security_context
          value: true
        # Mask sensitive data
        - type: regex_replace
          field: body
          pattern: '(password|token|key)=[^\\s]+'
          replacement: '${1}=***REDACTED***'

  processors:
    batch:
      timeout: 1s  # Quick processing for security events

    # Attribute processor to add security metadata
    attributes:
      actions:
        - key: security.classification
          value: sensitive
          action: upsert
        - key: data.sanitized
          value: true
          action: upsert

  exporters:
    # Encrypted transport for security logs
    otlphttp/security:
      logs_endpoint: https://security-pipeline.mezmo.com/v1/SECURITY_PIPELINE_ID
      headers:
        authorization: SECURITY_INGESTION_KEY
        x-security-classification: sensitive
      compression: gzip
      tls:
        insecure: false
        cert_file: /etc/ssl/certs/client.crt
        key_file: /etc/ssl/private/client.key

  service:
    pipelines:
      logs:
        receivers: [filelog]
        processors: [attributes, batch]
        exporters: [otlphttp/security]

---

# Multi-tenant configuration
multi_tenant: |
  receivers:
    filelog/tenant1:
      include:
        - /var/log/tenant1/*.log
      operators:
        - type: add
          field: attributes.tenant_id
          value: tenant1

    filelog/tenant2:
      include:
        - /var/log/tenant2/*.log
      operators:
        - type: add
          field: attributes.tenant_id
          value: tenant2

  processors:
    batch:
      timeout: 1s

    # Route based on tenant
    routing:
      from_attribute: tenant_id
      default_exporters: [otlphttp/default]
      table:
        - value: tenant1
          exporters: [otlphttp/tenant1]
        - value: tenant2
          exporters: [otlphttp/tenant2]

  exporters:
    otlphttp/tenant1:
      logs_endpoint: https://pipeline.mezmo.com/v1/TENANT1_PIPELINE_ID
      headers:
        authorization: TENANT1_INGESTION_KEY

    otlphttp/tenant2:
      logs_endpoint: https://pipeline.mezmo.com/v1/TENANT2_PIPELINE_ID
      headers:
        authorization: TENANT2_INGESTION_KEY

    otlphttp/default:
      logs_endpoint: https://pipeline.mezmo.com/v1/DEFAULT_PIPELINE_ID
      headers:
        authorization: DEFAULT_INGESTION_KEY

  service:
    pipelines:
      logs:
        receivers: [filelog/tenant1, filelog/tenant2]
        processors: [routing, batch]
        exporters: []  # Routing processor handles export

---

# ===== CURRENT IMPLEMENTATION CONFIGURATION =====

# This configuration matches the exact output of the restaurant app's generateOTELConfig function
# Updated to reflect the actual implementation as of the OTEL Mezmo integration fix
current_implementation: |
  # Generated by restaurant app's generateOTELConfig function
  # Service configuration matches current ConfigManager settings
  
  receivers:
    # File-based log collection for structured application logs
    filelog:
      include:
        - /tmp/codeuser/access.log          # HTTP access logs
        - /tmp/codeuser/events.log          # Business event logs 
        - /tmp/codeuser/performance.log     # Performance metrics logs
        - /tmp/codeuser/restaurant-performance.log  # Restaurant-specific performance
        - /tmp/codeuser/errors.log          # Error and exception logs
        - /tmp/codeuser/metrics.log         # Application metrics logs
        - /tmp/codeuser/app.log            # General application logs
      start_at: beginning
      operators:
        - type: add
          field: attributes.log_type
          value: structured
        - type: add
          field: attributes.service
          value: restaurant-app  # Matches ConfigManager serviceName

    # Host system metrics collection
    hostmetrics:
      collection_interval: 30s
      scrapers:
        cpu:
          metrics:
            system.cpu.utilization:
              enabled: true
        memory:
          metrics:
            system.memory.utilization:
              enabled: true
        disk:
          metrics:
            system.disk.io:
              enabled: true
        filesystem:
          metrics:
            system.filesystem.utilization:
              enabled: true
        network:
          metrics:
            system.network.io:
              enabled: true

    # OTLP receiver for frontend traces via backend proxy
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318
          cors:
            allowed_origins:
              - http://localhost:8080  # Frontend development server
              - http://localhost:3000  # Alternative frontend port
            allowed_headers: ['*']
            max_age: 7200

  processors:
    # Batch processing for efficiency (matches implementation)
    batch:
      timeout: 1s
      send_batch_size: 1024

    # Resource attribution (matches ConfigManager values)
    resource:
      attributes:
        - key: service.name
          value: restaurant-app      # From ConfigManager serviceName
          action: upsert
        - key: service.version
          value: 1.0.0
          action: upsert
        - key: deployment.environment
          value: demo               # Current environment setting
          action: upsert
        - key: service.tags
          value: restaurant-app,otel  # From ConfigManager tags
          action: upsert

  exporters:
    # Debug file exporters (always included)
    file/logs:
      path: /tmp/codeuser/otel-logs-debug.json
      format: json

    logging/logs:
      loglevel: info

    # Mezmo pipeline exporters (dynamic based on configuration)
    # Logs pipeline - uses modern OTLP HTTP format
    otlphttp/logs:
      logs_endpoint: https://pipeline.use.dev.logdna.net/v1/5c7e0854-7705-11f0-b8ef-0260f52d7685  # From agents-config.json
      headers:
        authorization: hm1A1LKqG+Y3K9tp3P2Bx04Z5QFe3pSuiFoqBzrtpoQ=  # Base64 encoded from config
        content-type: application/x-protobuf

    # Metrics pipeline - uses OTLP HTTP format
    otlphttp/metrics:
      endpoint: https://pipeline.use.dev.logdna.net/v1/5c7e0854-7705-11f0-b8ef-0260f52d7685
      headers:
        authorization: SGYSgfVbGjj/NAbaiIt714G426rkkQlfydo1RUuiuYw=
        content-type: application/x-protobuf

    # Traces pipeline - uses OTLP HTTP format
    otlphttp/traces:
      endpoint: https://pipeline.use.dev.logdna.net/v1/5c7e0854-7705-11f0-b8ef-0260f52d7685
      headers:
        authorization: Vr4at+j5Y8G1jRiRGb/35yXbV+vUtOIoDtCXUXp3Da8=
        content-type: application/x-protobuf

  service:
    # Pipeline configuration (dynamic based on enabled pipelines)
    pipelines:
      logs:
        receivers: [filelog]
        processors: [resource, batch]
        exporters: [file/logs, otlphttp/logs]

      metrics:
        receivers: [hostmetrics]
        processors: [resource, batch]
        exporters: [otlphttp/metrics]

      traces:
        receivers: [otlp]
        processors: [resource, batch]
        exporters: [otlphttp/traces]

    # Telemetry configuration (matches implementation)
    telemetry:
      logs:
        level: info  # From debugLevel parameter
      metrics:
        address: 0.0.0.0:8888

---

# ===== RESTAURANT-APP SPECIFIC CONFIGURATION =====

# Tailored configuration for restaurant application
restaurant_app_specific: |
  receivers:
    filelog:
      include:
        - /tmp/codeuser/access.log
        - /tmp/codeuser/events.log
        - /tmp/codeuser/performance.log
        - /tmp/codeuser/restaurant-performance.log
        - /tmp/codeuser/errors.log
        - /tmp/codeuser/metrics.log
        - /tmp/codeuser/app.log
      start_at: beginning
      operators:
        # Parse JSON logs
        - type: json_parser
          parse_from: body
          if: 'body matches "^\\s*\\{"'
        
        # Parse CLF access logs
        - type: regex_parser
          regex: '^(?P<ip>\\S+) \\S+ \\S+ \\[(?P<timestamp>[^\\]]+)\\] "(?P<method>\\S+) (?P<url>\\S+) \\S+" (?P<status>\\d+) (?P<size>\\S+)'
          if: 'body matches "^\\S+ - - \\["'
        
        # Add business context
        - type: add
          field: attributes.business_type
          value: restaurant
        - type: add
          field: attributes.app_features
          value: ordering,reservations,payments

    hostmetrics:
      collection_interval: 30s
      scrapers:
        cpu: {}
        memory: {}
        disk: {}
        filesystem:
          include_fs_types:
            match_type: strict
            fs_types: [ext4, xfs]

    # Restaurant-specific custom metrics
    prometheus:
      config:
        scrape_configs:
          - job_name: 'restaurant-app'
            static_configs:
              - targets: ['localhost:3001']
            scrape_interval: 30s
            metrics_path: /metrics

    otlp:
      protocols:
        http:
          endpoint: 0.0.0.0:4318
          cors:
            allowed_origins:
              - http://localhost:8080  # Frontend
              - http://localhost:3001  # Backend

  processors:
    batch:
      timeout: 2s
      send_batch_size: 512

    resource:
      attributes:
        - key: service.name
          value: restaurant-app
          action: upsert
        - key: service.version
          value: ${APP_VERSION}
          action: upsert
        - key: business.type
          value: restaurant
          action: upsert

    # Transform business events
    transform:
      log_statements:
        - context: log
          statements:
            # Categorize HTTP status codes
            - set(attributes["http.status_category"], "success") where attributes["status"] >= 200 and attributes["status"] < 300
            - set(attributes["http.status_category"], "client_error") where attributes["status"] >= 400 and attributes["status"] < 500
            - set(attributes["http.status_category"], "server_error") where attributes["status"] >= 500
            
            # Categorize business events
            - set(attributes["business.category"], "revenue") where attributes["eventType"] == "order_created" or attributes["eventType"] == "payment_processed"
            - set(attributes["business.category"], "customer") where attributes["eventType"] == "reservation_created" or attributes["eventType"] == "user_registered"
            - set(attributes["business.category"], "operational") where attributes["eventType"] == "product_updated" or attributes["eventType"] == "inventory_changed"

  exporters:
    # Restaurant business metrics to specialized pipeline
    otlphttp/business:
      logs_endpoint: https://pipeline.mezmo.com/v1/RESTAURANT_BUSINESS_PIPELINE_ID
      headers:
        authorization: RESTAURANT_BUSINESS_INGESTION_KEY
        x-business-type: restaurant

    # Technical logs to main pipeline
    otlphttp/technical:
      logs_endpoint: https://pipeline.mezmo.com/v1/RESTAURANT_TECH_PIPELINE_ID
      headers:
        authorization: RESTAURANT_TECH_INGESTION_KEY

    # Performance metrics
    otlphttp/performance:
      endpoint: https://pipeline.mezmo.com/v1/RESTAURANT_PERF_PIPELINE_ID
      headers:
        authorization: RESTAURANT_PERF_INGESTION_KEY

    # Debug output for development
    file/debug:
      path: /tmp/codeuser/otel-restaurant-debug.json
      format: json

  service:
    pipelines:
      # Business events pipeline
      logs/business:
        receivers: [filelog]
        processors: [transform, resource, batch]
        exporters: [otlphttp/business, file/debug]

      # Technical logs pipeline
      logs/technical:
        receivers: [filelog]
        processors: [resource, batch]
        exporters: [otlphttp/technical]

      # Performance metrics pipeline
      metrics:
        receivers: [hostmetrics, prometheus]
        processors: [resource, batch]
        exporters: [otlphttp/performance]

      # Traces pipeline
      traces:
        receivers: [otlp]
        processors: [resource, batch]
        exporters: [otlphttp/technical]

    extensions: [health_check, pprof]
    telemetry:
      logs:
        level: info
      metrics:
        address: 0.0.0.0:8888

  extensions:
    health_check:
      endpoint: 0.0.0.0:13133
    pprof:
      endpoint: 0.0.0.0:1777

---

# ===== IMPLEMENTATION NOTES =====

# Configuration Pattern Analysis (Updated for Current Implementation)

# The restaurant app's OTEL integration follows these key patterns:

# 1. MULTI-PIPELINE ARCHITECTURE
#    - Separate pipelines for logs, metrics, and traces
#    - Each pipeline can be independently enabled/disabled
#    - Pipeline-specific ingestion keys and endpoints

# 2. CONFIGURATION SOURCES (Priority Order)
#    - agents-config.json file (highest priority)
#    - Server-side ConfigManager storage
#    - Built-in hardcoded defaults (lowest priority)

# 3. ENDPOINT FORMATS
#    - Modern: https://{host}/v1/{pipelineId} (with pipelineId)
#    - Legacy: https://{host} (without pipelineId)
#    - Development: pipeline.use.dev.logdna.net
#    - Integration: pipeline.use.int.logdna.net  
#    - Production: pipeline.mezmo.com

# 4. AUTHENTICATION
#    - Base64-encoded ingestion keys (modern pipelines)
#    - Bearer tokens (legacy format)
#    - Content-Type: application/x-protobuf

# 5. ERROR HANDLING
#    - Retry logic with exponential backoff
#    - Graceful degradation when collector unavailable
#    - Debug file outputs for troubleshooting

# 6. PERFORMANCE OPTIMIZATION
#    - 1024 batch size for efficiency
#    - 1-second batch timeout for responsiveness
#    - Resource attribution for proper tagging

---

# ===== USAGE GUIDE =====

# Configuration Selection Guide (Updated):

# FOR DEVELOPMENT:
# - current_implementation: Matches exact restaurant app output
# - development_debug: Enhanced debug features
# - basic_logs_only: Minimal testing setup

# FOR PRODUCTION:  
# - production_optimized: High-performance production setup
# - high_volume_logs: For high-traffic applications
# - security_focused: Security-sensitive environments

# FOR SPECIALIZED USE CASES:
# - multi_tenant: Multi-tenant applications
# - restaurant_app_specific: Business-specific customizations

# IMPLEMENTATION VALIDATION:

# To verify configuration matches current implementation:
# 1. Start restaurant app: npm run server
# 2. Generate config: curl -X POST http://localhost:3001/api/otel/configure
# 3. Compare with 'current_implementation' template above
# 4. Check generated config: ls -la /tmp/codeuser/otelcol/config.yaml

# TESTING STEPS:

# 1. Validate YAML syntax:
#    yq eval . config.yaml > /dev/null && echo "Valid YAML" || echo "Invalid YAML"

# 2. Test with OTEL Collector:
#    otelcol-contrib --config config.yaml --dry-run

# 3. Compare with generated config:
#    diff config.yaml /tmp/codeuser/otelcol/config.yaml

# 4. Test against Mezmo endpoints:
#    curl -X POST {endpoint} -H "Authorization: {key}" -d '{"test":"data"}'

# ENVIRONMENT SETUP:

# Development environment variables:
# export OTEL_SERVICE_NAME=restaurant-app-dev
# export OTEL_DEBUG_LEVEL=debug
# export MEZMO_DEV_LOGS_KEY=your-logs-key
# export MEZMO_DEV_METRICS_KEY=your-metrics-key  
# export MEZMO_DEV_TRACES_KEY=your-traces-key

# Production environment variables:
# export OTEL_SERVICE_NAME=restaurant-app
# export OTEL_DEBUG_LEVEL=info
# export MEZMO_PROD_LOGS_KEY=your-prod-logs-key
# export MEZMO_PROD_METRICS_KEY=your-prod-metrics-key
# export MEZMO_PROD_TRACES_KEY=your-prod-traces-key

# TROUBLESHOOTING:

# Common configuration issues:
# 1. Invalid ingestion key format -> Use base64 encoded keys
# 2. Wrong endpoint format -> Include /v1/{pipelineId} for modern pipelines
# 3. Missing CORS configuration -> Add allowed_origins for frontend traces
# 4. Incorrect file paths -> Use /tmp/codeuser/ for development
# 5. Port conflicts -> Ensure 4317 (gRPC) and 4318 (HTTP) are available

# Debug commands:
# - Check collector logs: tail -f /tmp/codeuser/otel-collector.log
# - Test collector health: curl http://localhost:13133
# - View collector metrics: curl http://localhost:8888/metrics
# - Check debug output: cat /tmp/codeuser/otel-*-debug.json

# INTEGRATION WITH RESTAURANT APP:

# The restaurant app's OTEL integration:
# 1. Loads configuration from agents-config.json on startup
# 2. Provides UI for configuration management on /agents page  
# 3. Generates collector config via /api/otel/configure endpoint
# 4. Manages collector process via /api/otel/start and /api/otel/stop
# 5. Provides real-time status via /api/otel/status endpoint
# 6. Proxies frontend traces via /api/traces/v1/traces endpoint

# For complete integration testing, see:
# - tests/otel-integration-tests.js
# - tests/otel-config-persistence-test.js
# - tests/otel-trace-performance-test.js
# - run-otel-tests.sh