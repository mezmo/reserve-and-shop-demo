# Parse and Normalize Different Log Formats
# Handles JSON, CLF, CSV, XML, and String formats from the restaurant application

# Initialize normalized structure
.log_format = "unknown"
.normalized_at = now()
.vector_processed = true

# Detect and parse JSON format logs
if starts_with(string!(.message), "{") {
    parsed_json, parse_err = parse_json(.message)
    if parse_err == null {
        .log_format = "json"
        
        # Merge parsed JSON into root
        . = merge(., parsed_json)
        
        # Standardize timestamp field
        if exists(.timestamp) {
            .@timestamp = parse_timestamp(string!(.timestamp), "%Y-%m-%dT%H:%M:%S%.fZ") ?? now()
        }
        
        # Standardize level field
        if exists(.level) {
            .log_level = downcase(string!(.level))
        }
        
        # Extract correlation IDs
        if exists(.traceId) {
            .trace_id = .traceId
            del(.traceId)
        }
        if exists(.sessionId) {
            .session_id = .sessionId  
            del(.sessionId)
        }
        if exists(.requestId) {
            .request_id = .requestId
            del(.requestId)
        }
        if exists(.correlationId) {
            .correlation_id = .correlationId
            del(.correlationId)
        }
        
        # Standardize service field
        if !exists(.service) {
            .service = "restaurant-app"
        }
        
        # Extract business event context
        if exists(.eventType) {
            .event_type = .eventType
            del(.eventType)
        }
        if exists(.orderId) {
            .order_id = .orderId
            del(.orderId)
        }
        if exists(.userId) {
            .user_id = .userId
            del(.userId)
        }
    }
}

# Detect and parse Common Log Format (CLF)
else if match(string!(.message), r'^(\S+) (\S+) (\S+) \[([^\]]+)\] "([^"]*)" (\d+) (\S+)') {
    .log_format = "clf"
    
    # Parse CLF pattern
    parsed_clf = parse_regex(string!(.message), r'^(?P<host>\S+) (?P<ident>\S+) (?P<authuser>\S+) \[(?P<timestamp>[^\]]+)\] "(?P<request>[^"]*)" (?P<status>\d+) (?P<size>\S+)')!
    
    . = merge(., parsed_clf)
    
    # Parse request string "METHOD /path HTTP/1.1"
    if exists(.request) {
        request_parts = parse_regex(string!(.request), r'^(?P<method>\S+) (?P<url>\S+) (?P<protocol>\S+)')
        if request_parts != null {
            .method = request_parts.method
            .url = request_parts.url
            .protocol = request_parts.protocol
        }
    }
    
    # Standardize fields
    .ip = if .host != "-" { .host } else { null }
    .status_code = parse_int(string!(.status))!
    .response_size = if .size != "-" { parse_int(string!(.size)) } else { null }
    
    # Parse CLF timestamp
    .@timestamp = parse_timestamp(string!(.timestamp), "%d/%b/%Y:%H:%M:%S %z")!
    .log_level = "info"
    .service = "restaurant-app"
    
    # Clean up
    del(.host)
    del(.ident) 
    del(.authuser)
    del(.request)
    del(.status)
    del(.size)
}

# Detect and parse CSV format
else if contains(string!(.message), '","') && starts_with(string!(.message), '"') {
    .log_format = "csv"
    
    # Parse CSV with proper quote handling
    csv_fields = parse_csv(string!(.message), delimiter: ",")!
    
    # Map to standard fields (assuming timestamp,level,message,metadata format)
    if length(csv_fields) >= 4 {
        .@timestamp = parse_timestamp(string!(csv_fields[0]), "%Y-%m-%dT%H:%M:%S%.fZ")!
        .log_level = downcase(string!(csv_fields[1]))
        .message = csv_fields[2]
        
        # Parse metadata JSON if present
        if length(string!(csv_fields[3])) > 0 {
            metadata_json, parse_err = parse_json(csv_fields[3])
            if parse_err == null {
                . = merge(., metadata_json)
            }
        }
    }
    
    .service = "restaurant-app"
}

# Detect and parse XML format
else if starts_with(string!(.message), "<log") {
    .log_format = "xml"
    
    # Simple XML parsing for basic structure
    # Extract timestamp
    timestamp_match = parse_regex(string!(.message), r'<timestamp>([^<]+)</timestamp>')
    if timestamp_match != null {
        .@timestamp = parse_timestamp(string!(timestamp_match.captures[0]), "%Y-%m-%dT%H:%M:%S%.fZ")!
    }
    
    # Extract level
    level_match = parse_regex(string!(.message), r'<level>([^<]+)</level>')
    if level_match != null {
        .log_level = downcase(string!(level_match.captures[0]))
    }
    
    # Extract message
    message_match = parse_regex(string!(.message), r'<message>([^<]+)</message>')  
    if message_match != null {
        .parsed_message = message_match.captures[0]
    }
    
    .service = "restaurant-app"
}

# Parse string format logs
else if match(string!(.message), r'^\d{4}-\d{2}-\d{2}[ T]\d{2}:\d{2}:\d{2}') {
    .log_format = "string"
    
    # Parse timestamp from beginning
    timestamp_match = parse_regex(string!(.message), r'^(\d{4}-\d{2}-\d{2}[ T]\d{2}:\d{2}:\d{2}[\.\d]*)')!
    .@timestamp = parse_timestamp(string!(timestamp_match.captures[0]), "%Y-%m-%d %H:%M:%S%.f")!
    
    # Extract log level
    level_match = parse_regex(string!(.message), r'\[(TRACE|DEBUG|INFO|WARN|ERROR|FATAL)\]')
    if level_match != null {
        .log_level = downcase(string!(level_match.captures[0]))
    } else {
        .log_level = "info"
    }
    
    # Extract message content (everything after timestamp and level)
    content_match = parse_regex(string!(.message), r'^\d{4}-\d{2}-\d{2}[ T]\d{2}:\d{2}:\d{2}[\.\d]*\s*(?:\[[\w]+\])?\s*(.+)')
    if content_match != null {
        .parsed_message = content_match.captures[0]
        
        # Try to parse JSON metadata at the end
        json_match = parse_regex(string!(.parsed_message), r'^(.+?)\s*(\{.+\})$')
        if json_match != null {
            .parsed_message = json_match.captures[0]
            metadata_json, parse_err = parse_json(json_match.captures[1])
            if parse_err == null {
                . = merge(., metadata_json)
            }
        }
    }
    
    .service = "restaurant-app"
}

# Fallback for unrecognized formats
else {
    .log_format = "raw"
    .@timestamp = now()
    .log_level = "info"
    .service = "restaurant-app"
    .parsed_message = .message
}

# Ensure required fields exist
if !exists(.@timestamp) {
    .@timestamp = now()
}
if !exists(.log_level) {
    .log_level = "info"
}
if !exists(.service) {
    .service = "restaurant-app"
}

# Add environment context if not present
if !exists(.environment) {
    .environment = get_env_var("NODE_ENV") ?? "unknown"
}

# Calculate processing latency
if exists(.timestamp) && .timestamp != null {
    original_time = parse_timestamp(string!(.timestamp), "%Y-%m-%dT%H:%M:%S%.fZ")
    if original_time != null {
        .processing_latency_ms = to_int((to_float(.@timestamp) - to_float(original_time)) * 1000)
    }
}

# Normalize common field names
if exists(.responseTime) {
    .response_time = .responseTime
    del(.responseTime)
}
if exists(.statusCode) {
    .status_code = .statusCode
    del(.statusCode)
}
if exists(.errorCode) {
    .error_code = .errorCode
    del(.errorCode)
}

# Add metadata about parsing
.parsing_metadata = {
    "original_format": .log_format,
    "parsed_at": now(),
    "vector_version": "0.34.0",
    "parsing_successful": true
}