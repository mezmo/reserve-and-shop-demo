# Context Enrichment and Metadata Addition
# Adds environment context, service metadata, and correlation enhancement

# Skip processing if marked for dropping
if .dropped_by_sampling == true {
    return
}

# Environment and Service Context Enrichment
# ===========================================

# Add deployment environment details
if !exists(.environment) || .environment == "unknown" {
    .environment = get_env_var("NODE_ENV") ?? "development"
}

# Add detailed environment metadata
.environment_metadata = {
    "deployment_env": .environment,
    "deployment_region": get_env_var("AWS_REGION") ?? get_env_var("REGION") ?? "us-east-1",
    "deployment_version": get_env_var("APP_VERSION") ?? "1.0.0",
    "deployment_commit": get_env_var("GIT_COMMIT") ?? "unknown",
    "deployment_timestamp": get_env_var("DEPLOY_TIMESTAMP") ?? "unknown"
}

# Service identification and metadata
.service_metadata = {
    "service_name": .service ?? "restaurant-app",
    "service_version": get_env_var("APP_VERSION") ?? "1.0.0",
    "service_instance": get_hostname() ?? get_env_var("HOSTNAME") ?? "unknown",
    "service_pid": get_env_var("PID") ?? to_string(get_env_var("PPID") ?? "unknown"),
    "service_uptime": get_env_var("UPTIME") ?? "unknown"
}

# Container and orchestration context
if get_env_var("KUBERNETES_SERVICE_HOST") != null {
    .orchestration = "kubernetes"
    .k8s_metadata = {
        "namespace": get_env_var("KUBERNETES_NAMESPACE") ?? "default",
        "pod_name": get_env_var("HOSTNAME") ?? "unknown",
        "service_account": get_env_var("KUBERNETES_SERVICE_ACCOUNT") ?? "default",
        "cluster_name": get_env_var("CLUSTER_NAME") ?? "unknown"
    }
} else if get_env_var("DOCKER_CONTAINER_ID") != null {
    .orchestration = "docker"
    .docker_metadata = {
        "container_id": get_env_var("DOCKER_CONTAINER_ID"),
        "image_name": get_env_var("DOCKER_IMAGE") ?? "restaurant-app",
        "image_tag": get_env_var("DOCKER_TAG") ?? "latest"
    }
} else {
    .orchestration = "bare_metal"
    .host_metadata = {
        "hostname": get_hostname() ?? "unknown",
        "os": get_env_var("OS") ?? "linux",
        "architecture": get_env_var("ARCH") ?? "x86_64"
    }
}

# Correlation Enhancement
# =======================

# Ensure correlation IDs exist and are properly formatted
if !exists(.trace_id) {
    # Try to extract from other fields
    if exists(.traceId) {
        .trace_id = .traceId
        del(.traceId)
    } else if exists(.correlation_id) {
        .trace_id = .correlation_id
    } else {
        # Generate new trace ID
        .trace_id = "trace_" + uuid_v4()
    }
}

# Ensure session ID exists for user interactions
if !exists(.session_id) && (exists(.sessionId) || exists(.user_id)) {
    if exists(.sessionId) {
        .session_id = .sessionId
        del(.sessionId)
    } else {
        .session_id = "session_" + uuid_v4()
    }
}

# Ensure request ID exists for API calls
if !exists(.request_id) && (exists(.requestId) || exists(.method)) {
    if exists(.requestId) {
        .request_id = .requestId
        del(.requestId)
    } else {
        .request_id = "req_" + uuid_v4()
    }
}

# Enhanced correlation for business events
if .event_type != null {
    .business_correlation = {
        "event_trace_id": .trace_id,
        "business_session": .session_id,
        "business_event_id": .event_type + "_" + format_timestamp!(now(), "%Y%m%d_%H%M%S") + "_" + uuid_v4()[0:8]
    }
    
    # Link related business events
    if .event_type == "payment_processed" && exists(.order_id) {
        .business_correlation.related_order = .order_id
    }
    
    if .event_type == "order_created" && exists(.user_id) {
        .business_correlation.customer_id = .user_id
    }
}

# Geographic and Network Context
# ===============================

# Add geographic context based on available data
if exists(.ip_subnet) {
    # In a real implementation, this would do GeoIP lookup
    # Simulating based on IP pattern
    if starts_with(string!(.ip_subnet), "10.") {
        .geographic_context = {
            "network_type": "internal",
            "location": "internal_network",
            "country": "US",
            "region": "internal"
        }
    } else if starts_with(string!(.ip_subnet), "192.168") {
        .geographic_context = {
            "network_type": "private",
            "location": "private_network", 
            "country": "US",
            "region": "local"
        }
    } else {
        .geographic_context = {
            "network_type": "public",
            "location": "unknown",
            "country": "unknown",
            "region": "unknown"
        }
    }
}

# Time Context Enrichment
# ========================

# Add temporal context
timestamp_val = .@timestamp
.time_context = {
    "hour_of_day": to_int(format_timestamp!(timestamp_val, "%H")),
    "day_of_week": to_int(format_timestamp!(timestamp_val, "%u")),
    "day_of_month": to_int(format_timestamp!(timestamp_val, "%d")),
    "month": to_int(format_timestamp!(timestamp_val, "%m")),
    "year": to_int(format_timestamp!(timestamp_val, "%Y")),
    "is_weekend": to_int(format_timestamp!(timestamp_val, "%u")) >= 6,
    "is_business_hours": (
        to_int(format_timestamp!(timestamp_val, "%H")) >= 9 && 
        to_int(format_timestamp!(timestamp_val, "%H")) <= 17 &&
        to_int(format_timestamp!(timestamp_val, "%u")) < 6
    )
}

# Add timezone context
.time_context.timezone = get_env_var("TZ") ?? "UTC"
.time_context.unix_timestamp = to_unix_timestamp(timestamp_val)

# Business Context Enrichment
# ============================

# Add business context based on event type and timing
if exists(.event_type) {
    .business_context = {}
    
    # Revenue events
    if .event_type == "order_created" || .event_type == "payment_processed" {
        .business_context.category = "revenue"
        .business_context.impact_level = "high"
        .business_context.kpi_relevant = true
        
        if exists(.amount) {
            # Classify order size
            if .amount > 100 {
                .business_context.order_size = "large"
            } else if .amount > 50 {
                .business_context.order_size = "medium"
            } else {
                .business_context.order_size = "small"
            }
        }
    }
    
    # Customer events
    else if .event_type == "user_registered" || .event_type == "reservation_created" {
        .business_context.category = "customer_acquisition"
        .business_context.impact_level = "medium"
        .business_context.kpi_relevant = true
    }
    
    # Operational events
    else if .event_type == "inventory_updated" {
        .business_context.category = "operations"
        .business_context.impact_level = "low"
        .business_context.kpi_relevant = false
    }
    
    # Add business hours context to events
    if .time_context.is_business_hours {
        .business_context.occurred_during_business_hours = true
    } else {
        .business_context.occurred_outside_business_hours = true
        if .time_context.hour_of_day >= 22 || .time_context.hour_of_day <= 6 {
            .business_context.occurred_during_quiet_hours = true
        }
    }
}

# Technical Context Enhancement
# =============================

# Add technical context for API calls
if exists(.method) && exists(.url) {
    .api_context = {
        "http_method": .method,
        "endpoint_path": .url_path ?? .url,
        "is_api_call": starts_with(string!(.url ?? ""), "/api/"),
        "is_health_check": (
            contains(string!(.url ?? ""), "/health") ||
            contains(string!(.url ?? ""), "/ping") ||
            contains(string!(.url ?? ""), "/status")
        )
    }
    
    # Classify endpoint types
    if starts_with(string!(.url ?? ""), "/api/orders") {
        .api_context.business_domain = "orders"
        .api_context.criticality = "high"
    } else if starts_with(string!(.url ?? ""), "/api/payments") {
        .api_context.business_domain = "payments" 
        .api_context.criticality = "critical"
    } else if starts_with(string!(.url ?? ""), "/api/menu") {
        .api_context.business_domain = "catalog"
        .api_context.criticality = "medium"
    } else if starts_with(string!(.url ?? ""), "/api/auth") {
        .api_context.business_domain = "authentication"
        .api_context.criticality = "high"
    }
}

# Performance Context
if exists(.response_time) || exists(.duration) {
    performance_val = .response_time ?? .duration ?? 0
    .performance_context = {
        "response_time_ms": performance_val,
        "performance_tier": .performance_tier ?? "unknown",
        "is_slow": performance_val > 1000,
        "is_very_slow": performance_val > 5000,
        "performance_percentile": (
            if performance_val <= 100 { "p50" } 
            else if performance_val <= 300 { "p75" }
            else if performance_val <= 1000 { "p90" } 
            else if performance_val <= 3000 { "p95" }
            else { "p99+" }
        )
    }
}

# Error Context Enhancement
# =========================

if .log_level == "error" || .log_level == "fatal" {
    .error_context = {
        "error_level": .log_level,
        "has_stack_trace": exists(.stack),
        "error_classification": .error_type ?? "unknown",
        "is_user_facing": exists(.status_code) && .status_code >= 400 && .status_code < 500,
        "is_system_error": exists(.status_code) && .status_code >= 500,
        "requires_immediate_attention": (
            .severity == "critical" || 
            .severity == "high" || 
            (.alert_generated == true)
        )
    }
    
    # Add error frequency context (simplified)
    error_signature = .error_code ?? .error_type ?? downcase(string!(.message ?? "unknown"))
    .error_context.error_signature = hash(error_signature)
    
    # Business impact assessment
    if .business_context.category == "revenue" || 
       .api_context.criticality == "critical" ||
       exists(.order_id) || exists(.payment_method) {
        .error_context.business_impact = "high"
    } else if .api_context.criticality == "high" {
        .error_context.business_impact = "medium"  
    } else {
        .error_context.business_impact = "low"
    }
}

# Observability Enhancement
# =========================

# Add observability metadata
.observability = {
    "data_source": "vector_pipeline",
    "processing_pipeline": "restaurant_app_logs",
    "enrichment_version": "1.0",
    "enriched_at": now(),
    "original_format": .parsing_metadata.original_format ?? "unknown"
}

# Add search and filtering tags
.tags = []

# Environment tags
.tags = push(.tags, "env:" + (.environment ?? "unknown"))
.tags = push(.tags, "service:" + (.service ?? "restaurant-app"))

# Business tags
if exists(.business_context) {
    .tags = push(.tags, "business_category:" + (.business_context.category ?? "unknown"))
    if .business_context.kpi_relevant == true {
        .tags = push(.tags, "kpi_relevant:true")
    }
}

# Technical tags
if exists(.api_context) {
    .tags = push(.tags, "api_domain:" + (.api_context.business_domain ?? "unknown"))
    .tags = push(.tags, "criticality:" + (.api_context.criticality ?? "unknown"))
}

# Error tags
if exists(.error_context) {
    .tags = push(.tags, "error_level:" + .error_context.error_level)
    .tags = push(.tags, "error_impact:" + .error_context.business_impact)
    if .error_context.requires_immediate_attention == true {
        .tags = push(.tags, "urgent:true")
    }
}

# Performance tags
if exists(.performance_context) {
    .tags = push(.tags, "perf_tier:" + .performance_context.performance_tier)
    .tags = push(.tags, "perf_percentile:" + .performance_context.performance_percentile)
}

# Alert tags
if .alert_generated == true {
    .tags = push(.tags, "alert:generated")
    .tags = push(.tags, "severity:" + (.severity ?? "unknown"))
    if exists(.issue_category) {
        .tags = push(.tags, "issue_category:" + .issue_category)
    }
}

# Sampling tags
if .sampled == true {
    .tags = push(.tags, "sampled:true")
    .tags = push(.tags, "represents_volume:" + to_string(.represents_volume ?? 1))
}

# Add final enrichment timestamp
.enriched_at = now()
.enrichment_latency_ms = to_int((to_float(.enriched_at) - to_float(.normalized_at ?? .enriched_at)) * 1000)

# Clean up intermediate fields
del(.normalized_at)
del(.parsing_metadata)
del(.sampling_metadata)