# Issue Detection and Alerting Based on Troubleshooting Playbook
# Converts 30+ troubleshooting patterns into real-time Vector alerts

# Initialize alert tracking
.alert_generated = false
.alerts = []
.severity = "info"
.issue_category = null
.alert_context = {}

# Database & Connection Issues Detection
# ===========================================

# 1. Database Connection Pool Exhaustion
if .log_level == "error" && 
   (contains(string!(.message ?? ""), "pool exhausted") || 
    contains(string!(.message ?? ""), "connection pool") ||
    .error_code == "DB_POOL_EXHAUSTED") {
    
    .alert_generated = true
    .severity = "critical"
    .issue_category = "database"
    .alerts = push(.alerts, {
        "alert_type": "db_pool_exhausted",
        "description": "Database connection pool exhausted",
        "runbook": "https://docs.company.com/runbooks/db-pool-exhaustion",
        "immediate_action": "Check pool utilization and restart if needed"
    })
    
    # Extract pool statistics if available
    if exists(.poolSize) {
        .pool_utilization = to_float(.activeConnections ?? 0) / to_float(.poolSize)
        .alert_context.pool_stats = {
            "pool_size": .poolSize,
            "active_connections": .activeConnections,
            "queue_length": .queueLength ?? 0,
            "utilization": .pool_utilization
        }
    }
}

# 2. Database Query Performance Issues  
if (.duration ?? .responseTime ?? .response_time ?? 0) > 1000 && 
   (contains(string!(.message ?? ""), "query") || exists(.query)) {
    
    .alert_generated = true
    .severity = if (.duration ?? .responseTime ?? .response_time ?? 0) > 5000 { "high" } else { "medium" }
    .issue_category = "performance"
    .alerts = push(.alerts, {
        "alert_type": "slow_database_query",
        "description": "Database query performance degraded",
        "threshold": 1000,
        "actual_duration": .duration ?? .responseTime ?? .response_time
    })
}

# 3. Database Connection Failures
if .log_level == "error" && 
   (contains(string!(.message ?? ""), "connection failed") ||
    contains(string!(.message ?? ""), "connection refused") ||
    .error_code == "DB_CONNECTION_FAILED") {
    
    .alert_generated = true
    .severity = "critical" 
    .issue_category = "database"
    .alerts = push(.alerts, {
        "alert_type": "db_connection_failure",
        "description": "Database connection failed",
        "immediate_action": "Check database availability and network connectivity"
    })
}

# Payment & Financial Processing Issues
# =====================================

# 4. Payment Gateway Failures
if .log_level == "error" && 
   (contains(string!(.message ?? ""), "payment") &&
    (contains(string!(.message ?? ""), "failed") || 
     contains(string!(.message ?? ""), "declined") ||
     .error_code == "PAYMENT_GATEWAY_ERROR")) {
    
    .alert_generated = true
    .severity = "high"
    .issue_category = "payment"
    .alerts = push(.alerts, {
        "alert_type": "payment_failure",
        "description": "Payment processing failure detected",
        "business_impact": true
    })
    
    # Track payment failure context
    if exists(.amount) {
        .alert_context.financial_impact = {
            "amount": .amount,
            "currency": .currency ?? "USD",
            "order_id": .order_id
        }
    }
}

# 5. Payment Gateway Timeouts
if (.response_time ?? .duration ?? 0) > 10000 && 
   contains(string!(.message ?? ""), "payment") {
    
    .alert_generated = true
    .severity = "high"
    .issue_category = "payment"
    .alerts = push(.alerts, {
        "alert_type": "payment_timeout",
        "description": "Payment gateway timeout",
        "timeout_threshold": 10000,
        "actual_duration": .response_time ?? .duration
    })
}

# Performance & Memory Issues
# ===========================

# 6. High Memory Usage
if exists(.memory_usage) && .memory_usage > 80.0 {
    .alert_generated = true
    .severity = if .memory_usage > 90.0 { "critical" } else { "medium" }
    .issue_category = "performance"
    .alerts = push(.alerts, {
        "alert_type": "high_memory_usage", 
        "description": "Memory usage exceeded threshold",
        "threshold": 80.0,
        "current_usage": .memory_usage
    })
}

# 7. High CPU Usage
if exists(.cpu_usage) && .cpu_usage > 80.0 {
    .alert_generated = true
    .severity = if .cpu_usage > 95.0 { "critical" } else { "medium" }
    .issue_category = "performance"
    .alerts = push(.alerts, {
        "alert_type": "high_cpu_usage",
        "description": "CPU usage exceeded threshold", 
        "threshold": 80.0,
        "current_usage": .cpu_usage
    })
}

# 8. API Response Time Degradation
if (.response_time ?? .duration ?? 0) > 2000 && 
   (exists(.method) || exists(.url) || exists(.endpoint)) {
    
    .alert_generated = true
    .severity = if (.response_time ?? .duration ?? 0) > 5000 { "high" } else { "medium" }
    .issue_category = "performance"
    .alerts = push(.alerts, {
        "alert_type": "api_response_degradation",
        "description": "API response time degraded",
        "endpoint": .url ?? .endpoint,
        "method": .method,
        "response_time": .response_time ?? .duration
    })
}

# Service Reliability Issues  
# ===========================

# 9. High Error Rate
if (.status_code ?? .status ?? 0) >= 500 {
    .alert_generated = true
    .severity = "high"
    .issue_category = "reliability"  
    .alerts = push(.alerts, {
        "alert_type": "server_error",
        "description": "Server error detected",
        "status_code": .status_code ?? .status,
        "endpoint": .url ?? .endpoint
    })
}

# 10. Authentication Service Issues
if .log_level == "error" && 
   (contains(string!(.message ?? ""), "authentication") ||
    contains(string!(.message ?? ""), "unauthorized") ||
    .error_code == "AUTH_SERVICE_TIMEOUT") {
    
    .alert_generated = true
    .severity = "high"
    .issue_category = "authentication"
    .alerts = push(.alerts, {
        "alert_type": "auth_service_failure",
        "description": "Authentication service failure",
        "immediate_action": "Check auth service availability"
    })
}

# 11. Rate Limiting Triggered
if (.status_code ?? .status ?? 0) == 429 || 
   .error_code == "RATE_LIMIT_EXCEEDED" {
    
    .alert_generated = true
    .severity = "medium"
    .issue_category = "reliability"
    .alerts = push(.alerts, {
        "alert_type": "rate_limit_exceeded",
        "description": "Rate limit exceeded",
        "client_ip": .ip ?? .client_ip,
        "endpoint": .url ?? .endpoint
    })
}

# User Experience Issues
# ======================

# 12. Order Processing Failures
if .event_type == "order_created" && .log_level == "error" {
    .alert_generated = true
    .severity = "high"
    .issue_category = "business"
    .alerts = push(.alerts, {
        "alert_type": "order_processing_failure",
        "description": "Order processing failed",
        "business_impact": true,
        "order_id": .order_id,
        "customer_impact": "high"
    })
}

# 13. Inventory Issues
if contains(string!(.message ?? ""), "inventory") && 
   (contains(string!(.message ?? ""), "low") || 
    contains(string!(.message ?? ""), "out of stock")) {
    
    .alert_generated = true
    .severity = "medium"
    .issue_category = "inventory"
    .alerts = push(.alerts, {
        "alert_type": "low_inventory",
        "description": "Inventory level critically low", 
        "product_id": .productId ?? .product_id,
        "current_stock": .currentStock ?? .current_stock
    })
}

# Integration & API Issues
# ========================

# 14. External Service Timeouts  
if .log_level == "error" && 
   (contains(string!(.message ?? ""), "timeout") ||
    contains(string!(.message ?? ""), "timed out")) && 
   !contains(string!(.message ?? ""), "database") {
    
    .alert_generated = true
    .severity = "medium"
    .issue_category = "integration"
    .alerts = push(.alerts, {
        "alert_type": "external_service_timeout",
        "description": "External service timeout",
        "service_url": .url ?? .service_url,
        "timeout_duration": .timeout ?? .duration
    })
}

# 15. Circuit Breaker Activation
if contains(string!(.message ?? ""), "circuit breaker") && 
   contains(string!(.message ?? ""), "open") {
    
    .alert_generated = true
    .severity = "high"
    .issue_category = "reliability"
    .alerts = push(.alerts, {
        "alert_type": "circuit_breaker_open",
        "description": "Circuit breaker opened",
        "breaker_name": .breakerName ?? .breaker_name,
        "failure_count": .failureCount ?? .failure_count
    })
}

# Logging & Telemetry Issues
# ===========================

# 16. Log Processing Errors
if .log_level == "error" && 
   (contains(string!(.message ?? ""), "logging") ||
    contains(string!(.message ?? ""), "telemetry")) {
    
    .alert_generated = true
    .severity = "low"
    .issue_category = "observability"
    .alerts = push(.alerts, {
        "alert_type": "telemetry_processing_error",
        "description": "Telemetry processing error"
    })
}

# Security & Compliance Issues  
# =============================

# 17. Security Violations
if contains(string!(.message ?? ""), "security") || 
   contains(string!(.message ?? ""), "unauthorized access") ||
   (.status_code ?? .status ?? 0) == 401 || 
   (.status_code ?? .status ?? 0) == 403 {
    
    .alert_generated = true
    .severity = if (.status_code ?? .status ?? 0) == 401 { "medium" } else { "high" }
    .issue_category = "security"
    .alerts = push(.alerts, {
        "alert_type": "security_violation",
        "description": "Security violation detected",
        "client_ip": .ip ?? .client_ip,
        "user_agent": .userAgent ?? .user_agent,
        "endpoint": .url ?? .endpoint
    })
}

# 18. File Upload Validation Failures
if .error_code == "FILE_VALIDATION_ERROR" {
    .alert_generated = true
    .severity = "medium"
    .issue_category = "security"
    .alerts = push(.alerts, {
        "alert_type": "file_validation_failure",
        "description": "File upload validation failed",
        "filename": .fileName ?? .filename,
        "validation_errors": .validationErrors ?? .validation_errors
    })
}

# Business Logic Issues
# =====================

# 19. Failed Business Events
if .event_type != null && .log_level == "error" {
    .alert_generated = true
    .severity = "high" 
    .issue_category = "business"
    .alerts = push(.alerts, {
        "alert_type": "business_event_failure",
        "description": "Business event processing failed",
        "event_type": .event_type,
        "business_impact": true
    })
}

# 20. Data Consistency Issues
if contains(string!(.message ?? ""), "consistency") ||
   contains(string!(.message ?? ""), "constraint violation") {
    
    .alert_generated = true
    .severity = "high"
    .issue_category = "data_integrity"
    .alerts = push(.alerts, {
        "alert_type": "data_consistency_violation",
        "description": "Data consistency violation detected"
    })
}

# Infrastructure Issues
# ======================

# 21. Disk Space Issues
if exists(.disk_usage) && .disk_usage > 85.0 {
    .alert_generated = true
    .severity = if .disk_usage > 95.0 { "critical" } else { "medium" }
    .issue_category = "infrastructure"
    .alerts = push(.alerts, {
        "alert_type": "high_disk_usage",
        "description": "Disk usage exceeded threshold",
        "current_usage": .disk_usage,
        "threshold": 85.0
    })
}

# 22. Network Issues
if exists(.network_errors) && .network_errors > 0 {
    .alert_generated = true
    .severity = "medium"
    .issue_category = "infrastructure" 
    .alerts = push(.alerts, {
        "alert_type": "network_errors",
        "description": "Network errors detected",
        "error_count": .network_errors
    })
}

# Failure Simulation Detection
# =============================

# 23. Failure Simulation Active
if .simulationActive == true || contains(string!(.message ?? ""), "simulation") {
    .alert_generated = true
    .severity = "info"
    .issue_category = "simulation"
    .alerts = push(.alerts, {
        "alert_type": "failure_simulation_active",
        "description": "Failure simulation is active",
        "simulation_type": .simulationType ?? .simulation_type,
        "expected_behavior": true
    })
}

# Add alert metadata
if .alert_generated {
    .alert_metadata = {
        "generated_at": now(),
        "vector_instance": get_hostname() ?? "unknown",
        "alert_count": length(.alerts),
        "correlation_id": .correlation_id ?? .trace_id ?? uuid_v4(),
        "environment": .environment ?? "unknown"
    }
    
    # Set alert priority based on severity and category
    .alert_priority = if .severity == "critical" {
        "P1"
    } else if .severity == "high" {
        "P2" 
    } else if .severity == "medium" {
        "P3"
    } else {
        "P4"
    }
    
    # Add escalation information
    .escalation_info = {
        "notify_oncall": .severity == "critical" || .severity == "high",
        "create_incident": .severity == "critical" || (.severity == "high" && .issue_category == "business"),
        "slack_channel": if .issue_category == "business" { "#business-alerts" } else { "#ops-alerts" }
    }
}

# Clean up temporary fields for downstream processing
if !.alert_generated {
    del(.alerts)
    del(.severity) 
    del(.issue_category)
    del(.alert_context)
}